# ðŸ“Š ACD Metrics and Analytics Guide

## Overview

The Autonomous Coding Dashboard tracks comprehensive metrics to provide visibility into autonomous coding operations, enabling optimization and cost management.

---

## Token Metrics

### Input Tokens
Tokens sent to the Claude API, including:
- System prompts
- Feature specifications
- Code context
- Previous conversation history

### Output Tokens
Tokens generated by Claude, including:
- Code implementations
- Explanations
- Tool calls
- Responses

### Cache Tokens
- **Cache Read Tokens** - Tokens retrieved from prompt cache (discounted pricing)
- **Cache Write Tokens** - Tokens written to prompt cache for future use

### Token Efficiency Formula
```
Cache Hit Rate = cache_read_tokens / (input_tokens + cache_read_tokens) * 100
```

Higher cache hit rates = lower costs and faster responses.

---

## Cost Metrics

### Cost Calculation
```
Session Cost = (input_tokens * input_rate) + 
               (output_tokens * output_rate) + 
               (cache_read_tokens * cache_rate)
```

### Current Rates (Claude Sonnet)
| Token Type | Rate per 1M tokens |
|------------|-------------------|
| Input | $3.00 |
| Output | $15.00 |
| Cache Read | $0.30 |
| Cache Write | $3.75 |

### Cost Benchmarks
| Metric | Target | Current |
|--------|--------|---------|
| Cost per feature | < $0.25 | ~$0.19 |
| Features per dollar | > 4 | ~5.2 |
| Session success rate | > 90% | 90.8% |

---

## Timing Metrics

### Wall Clock Time
Total elapsed time from session start to end, including:
- API latency
- Processing time
- Network delays

### API Latency
Time spent waiting for API responses.

### Duration Breakdown
```
Total Duration = API Latency + Processing Time + I/O Time
```

---

## Session Metrics

### Session States
| State | Description |
|-------|-------------|
| running | Session currently active |
| completed | Session finished successfully |
| failed | Session encountered an error |
| timeout | Session exceeded time limit |

### Success Rate
```
Success Rate = completed_sessions / total_sessions * 100
```

### Session Throughput
```
Features per Hour = features_completed / hours_elapsed
```

---

## Target Metrics

### Progress Tracking
| Metric | Description |
|--------|-------------|
| Total Features | Features defined in feature_list.json |
| Passing Features | Features marked as completed |
| Percent Complete | (passing / total) * 100 |

### Status Values
| Status | Description |
|--------|-------------|
| pending | Not yet started or in progress |
| active | Currently being worked on |
| complete | All features implemented |
| paused | Temporarily stopped |

---

## Database Queries

### Get Overall Progress
```sql
SELECT 
  SUM(passing_features) as completed,
  SUM(total_features) as total,
  ROUND(SUM(passing_features)::numeric / NULLIF(SUM(total_features), 0) * 100, 2) as percent
FROM targets WHERE enabled = true;
```

### Get Daily Costs
```sql
SELECT 
  DATE(started_at) as date,
  COUNT(*) as sessions,
  SUM(cost_usd) as total_cost,
  SUM(input_tokens + output_tokens) as total_tokens
FROM harness_sessions
GROUP BY DATE(started_at)
ORDER BY date DESC;
```

### Get Target Performance
```sql
SELECT 
  t.name,
  COUNT(s.id) as sessions,
  AVG(s.duration_ms) as avg_duration,
  SUM(s.cost_usd) as total_cost,
  t.passing_features,
  t.total_features
FROM targets t
LEFT JOIN harness_sessions s ON s.target_id = t.id
GROUP BY t.id
ORDER BY t.priority;
```

---

## API Endpoints

### Get Summary Statistics
```bash
curl http://localhost:3434/api/db/targets/summary
```

Response:
```json
{
  "data": {
    "totalTargets": 16,
    "enabledTargets": 16,
    "completeTargets": 9,
    "totalFeatures": 2460,
    "passingFeatures": 2040,
    "pendingFeatures": 420,
    "overallPercent": 82.93
  }
}
```

### Get Recent Sessions
```bash
curl http://localhost:3434/api/db/sessions?limit=20
```

### Get Daily Snapshots
```bash
curl http://localhost:3434/api/db/snapshots?days=7
```

---

## Optimization Tips

### Reduce Costs
1. **Maximize cache hit rate** - Reuse context across sessions
2. **Use efficient models** - Haiku for simple tasks, Sonnet for complex
3. **Batch similar features** - Process related features together

### Improve Success Rate
1. **Clear feature definitions** - Well-defined features reduce failures
2. **Proper test setup** - Ensure test environment is configured
3. **Handle edge cases** - Account for network issues and timeouts

### Increase Throughput
1. **Parallel execution** - Run multiple targets when possible
2. **Optimize prompts** - Reduce token usage in system prompts
3. **Incremental progress** - Save state frequently

---

*Metrics are the key to understanding and optimizing autonomous coding operations.*
